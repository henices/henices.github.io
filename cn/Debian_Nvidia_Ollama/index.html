<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Nvidia 驱动安装和 Ollama 的使用 | 安全代码</title><meta name="author" content="曼福吉"><meta name="copyright" content="曼福吉"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="根据同事反馈，高版本的 NVIDIA 驱动兼容性有问题，需要安装 Nvidia 驱动 525.147.05 ，过程中可能需要升级内核。 安装 Nvidia 驱动查看 Debian 上显卡安装情况。 12lspci -nn | egrep -i &quot;3d|display|vga&quot;  01:00.0 VGA compatible controller [0300]: NVIDIA C">
<meta property="og:type" content="article">
<meta property="og:title" content="Nvidia 驱动安装和 Ollama 的使用">
<meta property="og:url" content="https://usmacd.com/cn/Debian_Nvidia_Ollama/index.html">
<meta property="og:site_name" content="安全代码">
<meta property="og:description" content="根据同事反馈，高版本的 NVIDIA 驱动兼容性有问题，需要安装 Nvidia 驱动 525.147.05 ，过程中可能需要升级内核。 安装 Nvidia 驱动查看 Debian 上显卡安装情况。 12lspci -nn | egrep -i &quot;3d|display|vga&quot;  01:00.0 VGA compatible controller [0300]: NVIDIA C">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640">
<meta property="article:published_time" content="2024-07-25T16:00:00.000Z">
<meta property="article:modified_time" content="2025-01-01T16:00:00.000Z">
<meta property="article:author" content="曼福吉">
<meta property="article:tag" content="ai">
<meta property="article:tag" content="linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Nvidia 驱动安装和 Ollama 的使用",
  "url": "https://usmacd.com/cn/Debian_Nvidia_Ollama/",
  "image": "https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640",
  "datePublished": "2024-07-25T16:00:00.000Z",
  "dateModified": "2025-01-01T16:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "曼福吉",
      "url": "https://usmacd.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://usmacd.com/cn/Debian_Nvidia_Ollama/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Nvidia 驱动安装和 Ollama 的使用',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/self/atom-one-light.css"><link rel="stylesheet" href="/self/nord.css"><meta name="generator" content="Hexo 8.1.1"><link rel="alternate" href="/atom.xml" title="安全代码" type="application/atom+xml">
<link rel="alternate" href="/rss.xml" title="安全代码" type="application/rss+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">173</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/thoughts"><i class="fa-fw fas fa-cloud"></i><span> 想法</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/sitemap.xml"><span> sitemap</span></a></div><div class="menus_item"><a class="site-page" href="/random.html"><span> random</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">安全代码</span></a><a class="nav-page-title" href="/"><span class="site-name">Nvidia 驱动安装和 Ollama 的使用</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/thoughts"><i class="fa-fw fas fa-cloud"></i><span> 想法</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/sitemap.xml"><span> sitemap</span></a></div><div class="menus_item"><a class="site-page" href="/random.html"><span> random</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Nvidia 驱动安装和 Ollama 的使用</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-25T16:00:00.000Z" title="发表于 2024-07-26 00:00:00">2024-07-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-01T16:00:00.000Z" title="更新于 2025-01-02 00:00:00">2025-01-02</time></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>根据同事反馈，高版本的 NVIDIA 驱动兼容性有问题，需要安装 Nvidia 驱动 525.147.05 ，过程中可能需要升级内核。</p>
<h2 id="安装-Nvidia-驱动"><a href="#安装-Nvidia-驱动" class="headerlink" title="安装 Nvidia 驱动"></a>安装 Nvidia 驱动</h2><p>查看 Debian 上显卡安装情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">lspci -nn | egrep -i &quot;3d|display|vga&quot;  <br>01:00.0 VGA compatible controller [0300]: NVIDIA Corporation AD102 [GeForce RTX 4090] [10de:2684] (rev a1)<br></code></pre></td></tr></table></figure>

<p>查看驱动安装具体的情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">lsmod | grep nouveau  <br>nouveau              2433024  0  <br>mxm_wmi                16384  1 nouveau  <br>i2c_algo_bit           16384  1 nouveau  <br>drm_display_helper    184320  1 nouveau  <br>drm_ttm_helper         16384  1 nouveau  <br>ttm                    94208  2 drm_ttm_helper,nouveau  <br>drm_kms_helper        204800  2 drm_display_helper,nouveau  <br>drm                   614400  5 drm_kms_helper,drm_display_helper,drm_ttm_helper,ttm,nouveau  <br>video                  65536  2 asus_wmi,nouveau  <br>wmi                    36864  5 video,asus_wmi,wmi_bmof,mxm_wmi,nouveau  <br>button                 24576  1 nouveau<br></code></pre></td></tr></table></figure>

<p>看来安装的是开源版本的驱动 <code>nouveau</code>，需要先禁用。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;blacklist nouveau&quot;</span> | <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> /etc/modprobe.d/nouveau-blacklist.conf<br><span class="hljs-built_in">sudo</span> update-initramfs -u<br><span class="hljs-built_in">sudo</span> update-grub<br><span class="hljs-built_in">sudo</span> reboot<br></code></pre></td></tr></table></figure>

<p>重启后，执行 <code>lsmod | grep nouveau</code>  发现已经返回为空了，成功禁用。</p>
<p>执行命令<code> sudo apt install nvidia-driver firmware-misc-nonfree</code> 安装 NVIDIA Proprietary Driver 报错。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">Consult /var/lib/dkms/nvidia-current/525.147.05/build/make.log for more information.  <br>dpkg: error processing package nvidia-kernel-dkms (--configure):  <br>installed nvidia-kernel-dkms package post-installation script subprocess returned error exit status 10  <br>dpkg: dependency problems prevent configuration of nvidia-driver:  <br>nvidia-driver depends on nvidia-kernel-dkms (= 525.147.05-4~deb12u1) | nvidia-kernel-525.147.05 | nvidia-open-kernel-525.147.05 | nvidia-open-kernel-525.147.05; however:  <br> Package nvidia-kernel-dkms is not configured yet.  <br> Package nvidia-kernel-525.147.05 is not installed.  <br> Package nvidia-kernel-dkms which provides nvidia-kernel-525.147.05 is not configured yet.  <br> Package nvidia-open-kernel-525.147.05 is not installed.  <br> Package nvidia-open-kernel-525.147.05 is not installed.  <br>  <br>dpkg: error processing package nvidia-driver (--configure):  <br>dependency problems - leaving unconfigured  <br>Processing triggers for libc-bin (2.36-9+deb12u4) ...  <br>Processing triggers for initramfs-tools (0.142) ...  <br>update-initramfs: Generating /boot/initrd.img-6.1.0-18-amd64  <br>Processing triggers for update-glx (1.2.2) ...  <br>Processing triggers for glx-alternative-nvidia (1.2.2) ...  <br>update-alternatives: using /usr/lib/nvidia to provide /usr/lib/glx (glx) in auto mode  <br>Processing triggers for glx-alternative-mesa (1.2.2) ...  <br>Processing triggers for libc-bin (2.36-9+deb12u4) ...  <br>Processing triggers for initramfs-tools (0.142) ...  <br>update-initramfs: Generating /boot/initrd.img-6.1.0-18-amd64  <br>Errors were encountered while processing:  <br>nvidia-kernel-dkms  <br>nvidia-driver  <br>E: Sub-process /usr/bin/dpkg returned an error code (1)<br></code></pre></td></tr></table></figure>

<p>确认 debian 版本 <code>lsb_release -a</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">No LSB modules are available.  <br>Distributor ID: Debian  <br>Description:    Debian GNU/Linux 12 (bookworm)  <br>Release:        12  <br>Codename:       bookworm<br></code></pre></td></tr></table></figure>

<p>根据 stackexchange 上的回答 ，安全升级 Debian 内核的方法是使用 backports 安装。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;deb http://deb.debian.org/debian bookworm-backports main&quot;</span> | <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/debian-backports.list<br><span class="hljs-built_in">sudo</span> apt update<br><span class="hljs-built_in">sudo</span> apt install -t bookworm-backports linux-image-amd64<br><span class="hljs-built_in">sudo</span> reboot<br></code></pre></td></tr></table></figure>

<p>重新启动后，执行 <code>uname -a</code>  发现内核已经成功升级了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">uname -a                                                                          <br>Linux debian 6.7.12+bpo-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.7.12-1~bpo12+1 (2024-05-06) x86_64 GNU/Linux<br></code></pre></td></tr></table></figure>

<p>重新安装 NVIDIA Proprietary Driver <code>sudo apt install nvidia-driver firmware-misc-nonfree</code> ，这次没有报错了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">nvidia-smi    <br><br>NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0<br></code></pre></td></tr></table></figure>

<p>NVIDIA Proprietary Driver 525 感觉有问题，过了一段时间后机器出现重启现象，dmesg 显示错误 <code>ACPI BIOS Error (bug)</code> 。 </p>
<p>上网搜索错误，有人反馈是 525 驱动问题（不确定）。Debain 系统 Nvidia 驱动有更新，执行 <code>apt upgrade</code> 后成功升级到 535 。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext"># nvidia-smi<br><br>NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2<br></code></pre></td></tr></table></figure>

<p>升级 Nvidia 驱动到 535 后，暂未出现重启现象。</p>
<h2 id="安装-ollama"><a href="#安装-ollama" class="headerlink" title="安装 ollama"></a>安装 ollama</h2><p>执行下面的命令安装 Ollama</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">curl -fsSL https://ollama.com/install.sh | sh<br></code></pre></td></tr></table></figure>

<p>下载速度很慢，还是挂线路。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">export https_proxy=http://127.0.0.1:7890<br>export http_proxy=http://127.0.0.1:7890<br>curl -fsSL https://ollama.com/install.sh | sh<br></code></pre></td></tr></table></figure>

<p>挂上线路后，很快 Ollama 就安装成功了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">&gt;&gt;&gt; Downloading ollama...  <br>######################################################################## 100.0%#=#=-#  #                                                                        <br>&gt;&gt;&gt; Installing ollama to /usr/local/bin...  <br>&gt;&gt;&gt; Creating ollama user...  <br>&gt;&gt;&gt; Adding ollama user to render group...  <br>&gt;&gt;&gt; Adding ollama user to video group...  <br>&gt;&gt;&gt; Adding current user to ollama group...  <br>&gt;&gt;&gt; Creating ollama systemd service...  <br>&gt;&gt;&gt; Enabling and starting ollama service...  <br>Created symlink /etc/systemd/system/default.target.wants/ollama.service → /etc/systemd/system/ollama.service.  <br>&gt;&gt;&gt; NVIDIA GPU installed.<br></code></pre></td></tr></table></figure>

<p>ollama 下载 llama3 8b 和 qwen2 7b 模型，执行下面的命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">ollama pull llama3<br>ollama pull qwen2:7b<br></code></pre></td></tr></table></figure>

<p>测试 llama3 模型，运行正常。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">ollama run llama3  <br>&gt;&gt;&gt; hi  <br>Hi! It&#x27;s nice to meet you. Is there something I can help you with or would you like to chat?<br></code></pre></td></tr></table></figure>
<h2 id="升级-Ollama"><a href="#升级-Ollama" class="headerlink" title="升级 Ollama"></a>升级 Ollama</h2><p>Ollama 0.3.0 支持通过 llama3.1 进行工具调用，有必要升级。参见 [4]</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/local/bin/ollama<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">chmod</span> +x /usr/local/bin/ollama<br></code></pre></td></tr></table></figure>

<p>升级完毕，需要重启 Ollama 服务。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> systemctl daemon-reload<br><span class="hljs-built_in">sudo</span> systemctl restart ollama<br></code></pre></td></tr></table></figure>

<p>新版本的 Ollama 已经不是一个单独的文件，而是一个 <code>tar.gz</code> 的压缩包。<br>tar.tgz 中包含了 ollama 运行需要的动态库，在升级前需要将这些动态库删除。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -rf /usr/lib/ollama<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -rf /usr/local/lib/ollama<br><br>curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz<br><span class="hljs-built_in">sudo</span> tar -C /usr/local -xzf ollama-linux-amd64.tgz<br></code></pre></td></tr></table></figure>

<p>执行完上述命令后，启动 ollama 检查版本确认是否升级成功。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">ollama serve<br>ollama -v<br></code></pre></td></tr></table></figure>

<h2 id="配置-Ollama"><a href="#配置-Ollama" class="headerlink" title="配置 Ollama"></a>配置 Ollama</h2><p>如果需要在浏览器插件（比如沉浸翻译）中调用 Ollama api，涉及 Cross-Origin 访问，需要修改 Ollama 配置。</p>
<p>官方文档提到了相关的设置 [5]，用 vim 直接修改 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ollama.service 中，添加下面内容：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_HOST=*&quot;</span><br></code></pre></td></tr></table></figure>

<p>重启 Ollama 服务</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> systemctl daemon-reload<br><span class="hljs-built_in">sudo</span> systemctl restart ollama<br></code></pre></td></tr></table></figure>

<p>在远程主机上，查看 Ollama 端口侦听情况</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">apt install net-tools<br>netstat -antp | grep -i ollama  <br></code></pre></td></tr></table></figure>

<p>Ollama 默认侦听 127.0.0.1:11434</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">tcp        0      0 127.0.0.1:11434         0.0.0.0:*               LISTEN      50508/ollama<br></code></pre></td></tr></table></figure>

<p>利用 SSH 将远程主机 Ollama 侦听的端口 11434 转发到本地 127.0.0.1:11434</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">ssh -N -g -L 127.0.0.1:11434:127.0.0.1:11434 root@1.1.1.1  <span class="hljs-comment"># 将 1.1.1.1 替换成你的 ip</span><br></code></pre></td></tr></table></figure>
<h2 id="卸载-Ollama"><a href="#卸载-Ollama" class="headerlink" title="卸载 Ollama"></a>卸载 Ollama</h2><p>停止 Ollama 服务</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> systemctl stop ollama<br><span class="hljs-built_in">sudo</span> systemctl <span class="hljs-built_in">disable</span> ollama<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> /etc/systemd/system/ollama.service<br></code></pre></td></tr></table></figure>

<p>删除二进制文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">sudo rm $(which ollama)<br></code></pre></td></tr></table></figure>

<p>删除 Ollama 用户</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -r /usr/share/ollama<br><span class="hljs-built_in">sudo</span> userdel ollama<br><span class="hljs-built_in">sudo</span> groupdel ollama<br></code></pre></td></tr></table></figure>

<h2 id="Ollama-的使用"><a href="#Ollama-的使用" class="headerlink" title="Ollama 的使用"></a>Ollama 的使用</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">OLLAMA_ORIGINS=* OLLAMA_NUM_PARALLEL=16 ollama serve<br></code></pre></td></tr></table></figure>

<ul>
<li>OLLAMA_ORIGINS 跨域设置</li>
<li>OLLAMA_NUM_PARALLEL 支持的并行请求数量</li>
<li>OLLAMA_DEBUG 打印调试信息</li>
<li>OLLAMA_LLM_LIBRARY 支持下面的选项  rocm_v6 cpu cpu_avx cpu_avx2 cuda_v11 rocm_v5</li>
<li>OLLAMA_KEEP_ALIVE 模型在显存内加载的时间，默认为 5 分钟</li>
<li>OLLAMA_GPU_OVERHEAD 单独为每个 GPU 预留的 VRAM ，单位是字节</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/blob/main/envconfig/config.go">https://github.com/ollama/ollama/blob/main/envconfig/config.go</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">AsMap</span><span class="hljs-params">()</span></span> <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]EnvVar &#123;<br>	ret := <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]EnvVar&#123;<br>		<span class="hljs-string">&quot;OLLAMA_DEBUG&quot;</span>:             &#123;<span class="hljs-string">&quot;OLLAMA_DEBUG&quot;</span>, Debug(), <span class="hljs-string">&quot;Show additional debug information (e.g. OLLAMA_DEBUG=1)&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_FLASH_ATTENTION&quot;</span>:   &#123;<span class="hljs-string">&quot;OLLAMA_FLASH_ATTENTION&quot;</span>, FlashAttention(), <span class="hljs-string">&quot;Enabled flash attention&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_HOST&quot;</span>:              &#123;<span class="hljs-string">&quot;OLLAMA_HOST&quot;</span>, Host(), <span class="hljs-string">&quot;IP Address for the ollama server (default 127.0.0.1:11434)&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_KEEP_ALIVE&quot;</span>:        &#123;<span class="hljs-string">&quot;OLLAMA_KEEP_ALIVE&quot;</span>, KeepAlive(), <span class="hljs-string">&quot;The duration that models stay loaded in memory (default \&quot;5m\&quot;)&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_LLM_LIBRARY&quot;</span>:       &#123;<span class="hljs-string">&quot;OLLAMA_LLM_LIBRARY&quot;</span>, LLMLibrary(), <span class="hljs-string">&quot;Set LLM library to bypass autodetection&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_MAX_LOADED_MODELS&quot;</span>: &#123;<span class="hljs-string">&quot;OLLAMA_MAX_LOADED_MODELS&quot;</span>, MaxRunners(), <span class="hljs-string">&quot;Maximum number of loaded models per GPU&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_MAX_QUEUE&quot;</span>:         &#123;<span class="hljs-string">&quot;OLLAMA_MAX_QUEUE&quot;</span>, MaxQueue(), <span class="hljs-string">&quot;Maximum number of queued requests&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_MODELS&quot;</span>:            &#123;<span class="hljs-string">&quot;OLLAMA_MODELS&quot;</span>, Models(), <span class="hljs-string">&quot;The path to the models directory&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_NOHISTORY&quot;</span>:         &#123;<span class="hljs-string">&quot;OLLAMA_NOHISTORY&quot;</span>, NoHistory(), <span class="hljs-string">&quot;Do not preserve readline history&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_NOPRUNE&quot;</span>:           &#123;<span class="hljs-string">&quot;OLLAMA_NOPRUNE&quot;</span>, NoPrune(), <span class="hljs-string">&quot;Do not prune model blobs on startup&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_NUM_PARALLEL&quot;</span>:      &#123;<span class="hljs-string">&quot;OLLAMA_NUM_PARALLEL&quot;</span>, NumParallel(), <span class="hljs-string">&quot;Maximum number of parallel requests&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_ORIGINS&quot;</span>:           &#123;<span class="hljs-string">&quot;OLLAMA_ORIGINS&quot;</span>, Origins(), <span class="hljs-string">&quot;A comma separated list of allowed origins&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_RUNNERS_DIR&quot;</span>:       &#123;<span class="hljs-string">&quot;OLLAMA_RUNNERS_DIR&quot;</span>, RunnersDir(), <span class="hljs-string">&quot;Location for runners&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_SCHED_SPREAD&quot;</span>:      &#123;<span class="hljs-string">&quot;OLLAMA_SCHED_SPREAD&quot;</span>, SchedSpread(), <span class="hljs-string">&quot;Always schedule model across all GPUs&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_TMPDIR&quot;</span>:            &#123;<span class="hljs-string">&quot;OLLAMA_TMPDIR&quot;</span>, TmpDir(), <span class="hljs-string">&quot;Location for temporary files&quot;</span>&#125;,<br>	&#125;<br>	<span class="hljs-keyword">if</span> runtime.GOOS != <span class="hljs-string">&quot;darwin&quot;</span> &#123;<br>		ret[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>, CudaVisibleDevices(), <span class="hljs-string">&quot;Set which NVIDIA devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;HIP_VISIBLE_DEVICES&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;HIP_VISIBLE_DEVICES&quot;</span>, HipVisibleDevices(), <span class="hljs-string">&quot;Set which AMD devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;ROCR_VISIBLE_DEVICES&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;ROCR_VISIBLE_DEVICES&quot;</span>, RocrVisibleDevices(), <span class="hljs-string">&quot;Set which AMD devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;GPU_DEVICE_ORDINAL&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;GPU_DEVICE_ORDINAL&quot;</span>, GpuDeviceOrdinal(), <span class="hljs-string">&quot;Set which AMD devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;HSA_OVERRIDE_GFX_VERSION&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;HSA_OVERRIDE_GFX_VERSION&quot;</span>, HsaOverrideGfxVersion(), <span class="hljs-string">&quot;Override the gfx used for all detected AMD GPUs&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;OLLAMA_INTEL_GPU&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;OLLAMA_INTEL_GPU&quot;</span>, IntelGPU(), <span class="hljs-string">&quot;Enable experimental Intel GPU detection&quot;</span>&#125;<br>	&#125;<br>	<span class="hljs-keyword">return</span> ret<br>&#125;<br></code></pre></td></tr></table></figure>

<p>可以使用 <code>ollama serve -h</code> 查看官方明确支持的环境变量。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs sh">ollama serve -h  <br>Start ollama  <br>  <br>Usage:  <br> ollama serve [flags]  <br>  <br>Aliases:  <br> serve, start  <br>  <br>Flags:  <br> -h, --<span class="hljs-built_in">help</span>   <span class="hljs-built_in">help</span> <span class="hljs-keyword">for</span> serve  <br>  <br>Environment Variables:  <br>     OLLAMA_DEBUG               Show additional debug information (e.g. OLLAMA_DEBUG=1)  <br>     OLLAMA_HOST                IP Address <span class="hljs-keyword">for</span> the ollama server (default 127.0.0.1:11434)  <br>     OLLAMA_KEEP_ALIVE          The duration that models stay loaded <span class="hljs-keyword">in</span> memory (default <span class="hljs-string">&quot;5m&quot;</span>)  <br>     OLLAMA_MAX_LOADED_MODELS   Maximum number of loaded models per GPU  <br>     OLLAMA_MAX_QUEUE           Maximum number of queued requests  <br>     OLLAMA_MODELS              The path to the models directory  <br>     OLLAMA_NUM_PARALLEL        Maximum number of parallel requests  <br>     OLLAMA_NOPRUNE             Do not prune model blobs on startup  <br>     OLLAMA_ORIGINS             A comma separated list of allowed origins  <br>     OLLAMA_SCHED_SPREAD        Always schedule model across all GPUs  <br>                                   <br>     OLLAMA_FLASH_ATTENTION     Enabled flash attention  <br>     OLLAMA_KV_CACHE_TYPE       Quantization <span class="hljs-built_in">type</span> <span class="hljs-keyword">for</span> the K/V cache (default: f16)  <br>     OLLAMA_LLM_LIBRARY         Set LLM library to bypass autodetection  <br>     OLLAMA_GPU_OVERHEAD        Reserve a portion of VRAM per GPU (bytes)  <br>     OLLAMA_LOAD_TIMEOUT        How long to allow model loads to stall before giving up (default <span class="hljs-string">&quot;5m&quot;</span>)<br></code></pre></td></tr></table></figure>


<h3 id="切换-Ollama-的模型文件位置"><a href="#切换-Ollama-的模型文件位置" class="headerlink" title="切换 Ollama 的模型文件位置"></a>切换 Ollama 的模型文件位置</h3><ul>
<li>OLLAMA_MODELS 环境变量可以修改模型文件下载的位置。</li>
</ul>
<p>先把选择下载的模型文件移动到新创建的 <code>/mnt/disk</code> , 默认存在的位置是  <code>~/.ollama/models</code><br>（使用 Ollama 官方的脚本安装，默认路径是 <code>/usr/share/ollama/.ollama/</code>）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mv</span> ~/.ollama/ /mnt/disk/<br><span class="hljs-built_in">ln</span> -s /mnt/disk/.ollama ~/.ollama<br></code></pre></td></tr></table></figure>

<p>重新 Ollama 启动测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">NVIDIA_VISIBLE_DEVICES=all CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 OLLAMA_ORIGINS=* OLLAMA_NUM_PARALLEL=16 OLLAMA_KEEP_ALIVE=10m ollama serve<br></code></pre></td></tr></table></figure>

<p>测试成功。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">root@pm-65c50001:~# ollama run llama3:8b-instruct-fp16  <br>&gt;&gt;&gt; hi  <br>Hi! It&#x27;s nice to meet you. Is there something I can help you with or would you like to chat?<br></code></pre></td></tr></table></figure>

<h3 id="研究-Ollama-mutlple-GPU"><a href="#研究-Ollama-mutlple-GPU" class="headerlink" title="研究 Ollama mutlple GPU"></a>研究 Ollama mutlple GPU</h3><p>在 <a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/issues/4198">https://github.com/ollama/ollama/issues/4198</a> 中发现一些比较重要的环境变量。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">[Unit]  <br>Description=Ollama Service  <br>After=network-online.target<br><br>[Service]  <br>Environment=&quot;OLLAMA_HOST=0.0.0.0:11434&quot;  <br>Environment=&quot;OLLAMA_ORIGINS=&#x27;*&#x27;&quot;  <br>Environment=&quot;OLLAMA_MODELS=/ollama/ollama/models&quot;  <br>Environment=&quot;OLLAMA_KEEP_ALIVE=10m&quot;  <br>Environment=&quot;OLLAMA_NUM_PARALLEL=4&quot;<br>Environment=&quot;OLLAMA_MAX_LOADED_MODELS=2&quot;  <br>Environment=&quot;CUDA_VISIBLE_DEVICES=0,1,2,3&quot;  <br>ExecStart=/usr/local/bin/ollama serve  <br>User=ollama  <br>Group=ollama  <br>Restart=always  <br>RestartSec=3  <br>Environment=&quot;PATH=/root/.local/bin:/root/bin:/usr/lib64/ccache:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin&quot;<br><br>[Install]  <br>WantedBy=default.target<br></code></pre></td></tr></table></figure>

<p>综合一下，决定使用下面的命令行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">NVIDIA_VISIBLE_DEVICES=all CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 OLLAMA_ORIGINS=* OLLAMA_NUM_PARALLEL=16 OLLAMA_KEEP_ALIVE=10m ollama serve<br></code></pre></td></tr></table></figure>

<h3 id="如何判断模型是否加载入-GPU"><a href="#如何判断模型是否加载入-GPU" class="headerlink" title="如何判断模型是否加载入 GPU"></a>如何判断模型是否加载入 GPU</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">ollama ps<br>NAME      	ID          	SIZE 	PROCESSOR	UNTIL<br>llama3:70b	bcfb190ca3a7	42 GB	100% GPU 	4 minutes from now<br></code></pre></td></tr></table></figure>

<ul>
<li>48%&#x2F;52% CPU&#x2F;GPU 类似这样的显示，说明模型只有部分加载入 GPU，还有一部分加载入系统的内存</li>
</ul>
<h3 id="内核设置-numa-balancing"><a href="#内核设置-numa-balancing" class="headerlink" title="内核设置 numa_balancing"></a>内核设置 numa_balancing</h3><p>Ollama 0.3.6 加载  Llama 3.1 405b 失败，界面一直卡着不动，在 Github 上看到类似问题。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/issues/6425">https://github.com/ollama/ollama/issues/6425</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">time=2024-08-29T10:50:24.720+08:00 level=INFO source=sched.go:445 msg=&quot;loaded runners&quot; count=1<br>time=2024-08-29T10:50:24.720+08:00 level=INFO source=server.go:593 msg=&quot;waiting for llama runner to start responding&quot;<br>time=2024-08-29T10:50:24.720+08:00 level=INFO source=server.go:627 msg=&quot;waiting for server to become available&quot; status=&quot;llm server error&quot;<br>WARNING: /proc/sys/kernel/numa_balancing is enabled, this has been observed to impair performance<br></code></pre></td></tr></table></figure>

<p>上面的 Issue 提到   有影响，手工禁用并使用 Ollama 0.3.8 可以解决问题。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> 0 &gt; /proc/sys/kernel/numa_balancing  <span class="hljs-comment"># or</span><br>sysctl -w kernel.numa_balancing=0<br></code></pre></td></tr></table></figure>

<p>学习 <code>/numa_balancing</code> 的作用，看上去像优化内存使用。<br><a target="_blank" rel="noopener" href="https://docs.kernel.org/admin-guide/sysctl/kernel.html#numa-balancing">https://docs.kernel.org/admin-guide/sysctl/kernel.html#numa-balancing</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">Enables/disables and configures automatic page fault based NUMA memory balancing<br></code></pre></td></tr></table></figure>

<p>Ollama 从 0.37 开始不再是一个独立的 X86_64 的 elf，而是一个 tar.gz<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/releases/download/v0.3.8/ollama-linux-amd64.tgz">https://github.com/ollama/ollama/releases/download/v0.3.8/ollama-linux-amd64.tgz</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs plaintext"># cd root<br># tar zxvf ollama-linux-amd64.tgz    <br>./  <br>./lib/  <br>./lib/ollama/  <br>./lib/ollama/libcublas.so.12.4.2.65  <br>./lib/ollama/libcublasLt.so.11  <br>./lib/ollama/libcublas.so.11.5.1.109  <br>./lib/ollama/libcudart.so.11.3.109  <br>./lib/ollama/libcublas.so.12  <br>./lib/ollama/libcublasLt.so  <br>./lib/ollama/libcublas.so.11  <br>./lib/ollama/libcublas.so  <br>./lib/ollama/libcudart.so  <br>./lib/ollama/libcublasLt.so.12  <br>./lib/ollama/libcublasLt.so.11.5.1.109  <br>./lib/ollama/libcudart.so.11.0  <br>./lib/ollama/libcudart.so.12.4.99  <br>./lib/ollama/libcudart.so.12  <br>./lib/ollama/libcublasLt.so.12.4.2.65  <br>./bin/  <br>./bin/ollama<br></code></pre></td></tr></table></figure>


<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#export LD_LIBRARY_PATH=/root/lib/ollama/</span><br>OLLAMA_DEBUG=1 NVIDIA_VISIBLE_DEVICES=all CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 OLLAMA_ORIGINS=* OLLAMA_KEEP_ALIVE=10m /root/bin/ollama serve<br></code></pre></td></tr></table></figure>

<p>34s 后，Llama3.1 405b 成功启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">time=2024-08-29T15:07:02.113+08:00 level=INFO source=server.go:630 msg=&quot;llama runner started in 34.94 seconds&quot;<br></code></pre></td></tr></table></figure>


<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[0] NvidiaGraphicsDrivers<br><a target="_blank" rel="noopener" href="https://wiki.debian.org/NvidiaGraphicsDrivers">https://wiki.debian.org/NvidiaGraphicsDrivers</a></p>
<p>[1] Debain backports Instructions<br><a target="_blank" rel="noopener" href="https://backports.debian.org/Instructions/">https://backports.debian.org/Instructions/</a></p>
<p>[2] Ollama on Linux<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/blob/main/docs/linux.md">https://github.com/ollama/ollama/blob/main/docs/linux.md</a></p>
<p>[3] Is it possible &amp; safe to use latest kernel with Debian?<br><a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/725783/is-it-possible-safe-to-use-latest-kernel-with-debian">https://unix.stackexchange.com/questions/725783/is-it-possible-safe-to-use-latest-kernel-with-debian</a></p>
<p>[4] Ollama v0.3.0 release note<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/releases/tag/v0.3.0">https://github.com/ollama/ollama/releases/tag/v0.3.0</a></p>
<p>[5] Ollama FAQ<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server">https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://usmacd.com">曼福吉</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://usmacd.com/cn/Debian_Nvidia_Ollama/">https://usmacd.com/cn/Debian_Nvidia_Ollama/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://usmacd.com" target="_blank">安全代码</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/linux/">linux</a><a class="post-meta__tags" href="/tags/ai/">ai</a></div><div class="post-share"><div class="social-share" data-image="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/cn/android_apk_extract/" title="如何提取 Android 手机中已经安装的 APK 文件"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">如何提取 Android 手机中已经安装的 APK 文件</div></div><div class="info-2"><div class="info-item-1">首先需要下载 Android Platform Tools 获取 adb 工具。 Android Platform Tools 的下载地址为：https://developer.android.com/tools/releases/platform-tools#downloads 在本机执行下面命令，可以提取 Android 手机上安装的 apk 文件。 123adb shell pm list packagesadb shell pm path &lt;package name&gt;adb pull &lt;apk_path_on_device&gt;  如果要在另外一台手机上安装 Android 应用，则需要在本机执行另外两条命令。 12adb install base.apk # or adb install-multiple base.apk split_config.arm64_v8a.apk *.apk  注：本篇需要一些专业知识，至少需要知道 Android 应用 package name 的含义。 </div></div></div></a><a class="pagination-related" href="/cn/elon_philosophy/" title="马斯克的哲学"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">马斯克的哲学</div></div><div class="info-2"><div class="info-item-1">马斯克的五步工作法马斯克提炼出了一个五步工作法，称之为“算法”，自称每天的工作就是「算法复读机」😄️ 这五个步骤按顺序分别是: 1）质疑每项需求，让要求不那么愚蠢  提出任何一项要求时，都应该附上提出这一要求的人。 永远不要接受一项来自某个部门的要求，比如来自“法务部门”的要求。  2）删除要求当中所有你能删除的部分和流程  虽然你可能还得把它们加回来，如果最后加来的部分还不到删除部分的10%，那就说明删减得还不够。  3）简化和优化  这应该放在第2步之后，因为人们常犯的错误就是简化和优化一个原本不应该存在的部分或者流程。  4）加快周转时间  每个流程都可以加快，但只有遵循了前三个步骤之后才能这么做。  5）自动化  过早的自动化会产生问题，自动化是最后一个步骤，在此之前必须经过质疑、删除、简化等步骤  马斯克五步工作法的重要推论 所有技术经理都必须有实战经验，软件团队的管理人员至少花 20% 的时间编程 犯错没关系，但错了还不肯低头就不行 唯一要遵守的规则就是物理学定律能推导出来的规则，其他一切都只是建议 深度调研需要跨级沟通，直接和你下属的下属交流，不要只和你直接管理的...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/cn/ssd/" title="SSD 迁移记"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-20</div><div class="info-item-2">SSD 迁移记</div></div><div class="info-2"><div class="info-item-1">由于某些需求，决定上SSD，提高一下硬盘读写速度。上二手东买了三星(SAMSUNG) 860 EVO 最初的想法是作为数据盘使用，即操作系统还是跑在机械硬盘上，仔细一思考，还是折腾一下，要不实在是有些浪费，事实证明，折腾是值得的，感觉就像飞一样。 首先查看一下磁盘原始的情况： 1234$ mount/dev/sda1 on /boot type ext4 (rw,relatime,seclabel,stripe=4)/dev/mapper/fedora-root on / type ext4 (rw,relatime,seclabel)  当然首先要把 SSD 处理一下，安装一下 gparted 图形化界面很好用。 1sudo dnf install gparted  建个分区表，选择 gpt，分个区，/dev/mapper/fedora-root 大小为50G，先分个50G的分区，剩下的全部给 另外一个分区，格式化为 ext4。操作完成后，用fdisk 查看一下： 123456789101112$ fdisk -lDisk /dev/sdb：232.9 GiB，25005935...</div></div></div></a><a class="pagination-related" href="/cn/vnc/" title="Fedora 安装 vnc server"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-06</div><div class="info-item-2">Fedora 安装 vnc server</div></div><div class="info-2"><div class="info-item-1">因为疫情，现在公司启用远程办公了，不得已在工作机上开了vncserver，这篇文档做个记录。 (1) 安装1sudo dnf install tigervnc-server  (2) 创建服务1cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@.service  编辑 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;vncserver@.service 替换下面两行的USER为实际用户名 12ExecStart=/sbin/runuser -l USER -c &quot;/usr/bin/vncserver %i -geometry 1280x1024&quot;PIDFile=/home/USER/.vnc/%H%i.pid  执行命令 systemctl daemon-reload 使用vpnpasswd修改密码 1234~]# su - USER~]$ vncpasswdPassword:Verify:  启动vncserver的命令行 1sudo...</div></div></div></a><a class="pagination-related" href="/cn/010editor/" title="010editor 保持试用"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-06</div><div class="info-item-2">010editor 保持试用</div></div><div class="info-2"><div class="info-item-1">软件介绍010Editor是一款快速且强大的十六进制编辑器。用来编辑二进制文件。有一个友好易于使用的界面，无限次的undo和redo操作。另外还可以打印十六进制的字节或者以书签的方式标出某些重要的字节。支持二进制模板（binary template）系统。 保持试用国外软件很多时候相当厚道了，试用基本是全功能，轻微延时和不能自动更新二进制模板，就日常使用来说基本是完全够用了。 关键文件为 ~/.config/SweetScape/010 Editor.ini，无法使用的时侯可以把这个文件清空，将恢复30天试用状态，或者简单粗暴的将文件设置为只读。 1chmod 444 &quot;010 Editor.ini&quot;  用IDA逆向的时侯没有发现这个文件比较奇怪。这个文件是 是使用strace命令发现的，strace命令支持 -e 的过滤参数将有效减少输出，一般来说看strace日志文件可以从最后往前看。 1strace -e trace=file ./010editor  从代码上看有使用网络验证需要在hosts文件中屏敝两个网站， 可以减少一些不必要的麻烦。 12127....</div></div></div></a><a class="pagination-related" href="/cn/fedora_linux_7z/" title="Fedora Linux 升级系统中的 7-Zip"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-13</div><div class="info-item-2">Fedora Linux 升级系统中的 7-Zip</div></div><div class="info-2"><div class="info-item-1">早上四哥 (scz) 发了条微博，7-Zip 最近有相关的CVE，CVE-2025-11001、CVE-2025-11002，建议升级到 25.01。 如果使用 Windows 系统，在 https://7-zip.org/ 下载 7-Zip 25.01，升级安装即可。 在 Linux 系统中 7-zip 的版本比较复杂，关于 p7zip 和 7-zip 可以参考7-zip 官方readme.txt 的说明。 123456789101112131415161718192021222324252627282930313233343536377-Zip and p7zip===============Now there are two different ports of 7-Zip for Linux/macOS:1) p7zip - another port of 7-Zip for Linux, made by an independent developer.   The latest version of p7zip now is 16.02, and that p7zip...</div></div></div></a><a class="pagination-related" href="/cn/qemu_kvm/" title="VMware Workstation Windows 10 host Ubuntu 18.04 Guest 中加载 Linux 内核 kvm 模块"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-28</div><div class="info-item-2">VMware Workstation Windows 10 host Ubuntu 18.04 Guest 中加载 Linux 内核 kvm 模块</div></div><div class="info-2"><div class="info-item-1">这里在 VMware Workstation Guset OS 里使用 qemu 的用法，有点像俄罗斯套娃。 qemu.sh 123456789101112qemu-system-x86_64 \  -m 2G \  -smp 2 \  -kernel $KERNEL/arch/x86——64/boot/bzImage \  -append &quot;console=ttyS0 root=/dev/sda earlyprintk=serial net.ifnames=0&quot; \  -drive file=$IMAGE/bullseye.img,format=raw \  -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10021-:22 \  -net nic,model=e1000 \  -enable-kvm \  -nographic \  -pidfile vm.pid \  2&gt;&amp;1 | tee vm.log  执行命令后 bash ./qemu.sh 后报错 12Could not access K...</div></div></div></a><a class="pagination-related" href="/cn/chrome_flash_update/" title="Google Chrome 浏览器 Adobe Flash Player 升级"><img class="cover" src="https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2017-07-14</div><div class="info-item-2">Google Chrome 浏览器 Adobe Flash Player 升级</div></div><div class="info-2"><div class="info-item-1">某一天突然发现网页中flash已经不能正常显示了（我一般都禁用），显示 out of data 错误。 访问 chrome:&#x2F;&#x2F;components&#x2F; 可以升级 Adobe Flash Player Adobe Flash Player - 检查更新， 失败。这里有一个坑，插件中的代理设置是无法影响chrome 内部程序的，必须设置环境变量或者直接使用命令行来设置全局代理。 google-chrome —proxy-server&#x3D;”socks:&#x2F;&#x2F;127.0.0.1:9999” 重新检查更新，可以成功更新了，重启后生效了，已经不报 out of data 错误了。为了保险把系统中flash player也给升级，打开网页 https://get.adobe.com/flashplayer/otherversions/ step 1 选Linux (64 bit), step 2 选 yum，下载后安装，后续可以使用dnf 升级了。 </div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">曼福吉</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">173</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="/rss.xml" target="_blank" title="RSS"><i class="fas fa-rss" style="color: #4c566a;"></i></a><a class="social-icon" href="https://x.com/henices" target="_blank" title="Twitter"><i class="fab fa-x-twitter" style="color: #4c566a;"></i></a><a class="social-icon" href="mailto:zhouzhenster@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4c566a;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-Nvidia-%E9%A9%B1%E5%8A%A8"><span class="toc-number">1.</span> <span class="toc-text">安装 Nvidia 驱动</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-ollama"><span class="toc-number">2.</span> <span class="toc-text">安装 ollama</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%87%E7%BA%A7-Ollama"><span class="toc-number">3.</span> <span class="toc-text">升级 Ollama</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-Ollama"><span class="toc-number">4.</span> <span class="toc-text">配置 Ollama</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B8%E8%BD%BD-Ollama"><span class="toc-number">5.</span> <span class="toc-text">卸载 Ollama</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ollama-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">6.</span> <span class="toc-text">Ollama 的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%8D%A2-Ollama-%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6%E4%BD%8D%E7%BD%AE"><span class="toc-number">6.1.</span> <span class="toc-text">切换 Ollama 的模型文件位置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6-Ollama-mutlple-GPU"><span class="toc-number">6.2.</span> <span class="toc-text">研究 Ollama mutlple GPU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%90%A6%E5%8A%A0%E8%BD%BD%E5%85%A5-GPU"><span class="toc-number">6.3.</span> <span class="toc-text">如何判断模型是否加载入 GPU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E8%AE%BE%E7%BD%AE-numa-balancing"><span class="toc-number">6.4.</span> <span class="toc-text">内核设置 numa_balancing</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">7.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/cn/gemini_in_chrome/" title="开启 Gemini in Chrome 的方法">开启 Gemini in Chrome 的方法</a><time datetime="2026-01-29T16:00:00.000Z" title="发表于 2026-01-30 00:00:00">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/cn/sucess_is_the_mother_of_sucess/" title="成功是成功之母">成功是成功之母</a><time datetime="2026-01-27T16:00:00.000Z" title="发表于 2026-01-28 00:00:00">2026-01-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/cn/ai_studio_podcast_transcript/" title="利用 AI Studio 整理播客音频的逐字稿">利用 AI Studio 整理播客音频的逐字稿</a><time datetime="2026-01-07T16:00:00.000Z" title="发表于 2026-01-08 00:00:00">2026-01-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/cn/anti-weakness-learning/" title="反脆弱式的学习方法">反脆弱式的学习方法</a><time datetime="2025-12-30T16:00:00.000Z" title="发表于 2025-12-31 00:00:00">2025-12-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/cn/keep_hard/" title="坚持的秘诀">坚持的秘诀</a><time datetime="2025-12-15T16:00:00.000Z" title="发表于 2025-12-16 00:00:00">2025-12-16</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://images.unsplash.com/photo-1646026371686-79950ceb6daa?w=640);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 曼福吉</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><script src="/js/tw_cn.js?v=5.5.4"></script><div class="js-pjax"><script>(() => {
  const parseViewBox = viewBox => {
    if (!viewBox) return null
    const parts = viewBox.trim().split(/[\s,]+/).map(n => Number(n))
    if (parts.length !== 4 || parts.some(n => Number.isNaN(n))) return null
    return parts
  }

  const getSvgViewBox = svg => {
    const attr = parseViewBox(svg.getAttribute('viewBox'))
    if (attr) return attr

    // Fallback: use bbox to build a viewBox
    try {
      const bbox = svg.getBBox()
      if (bbox && bbox.width && bbox.height) return [bbox.x, bbox.y, bbox.width, bbox.height]
    } catch (e) {
      // getBBox may fail on some edge cases; ignore
    }

    const w = Number(svg.getAttribute('width')) || 0
    const h = Number(svg.getAttribute('height')) || 0
    if (w > 0 && h > 0) return [0, 0, w, h]
    return [0, 0, 100, 100]
  }

  const setSvgViewBox = (svg, vb) => {
    svg.setAttribute('viewBox', `${vb[0]} ${vb[1]} ${vb[2]} ${vb[3]}`)
  }

  const clamp = (v, min, max) => Math.max(min, Math.min(max, v))

  const openSvgInNewTab = ({ source, initViewBox }) => {
    const getClonedSvg = () => {
      if (typeof source === 'string') {
        const template = document.createElement('template')
        template.innerHTML = source.trim()
        const svg = template.content.querySelector('svg')
        return svg ? svg.cloneNode(true) : null
      }
      if (source && typeof source.cloneNode === 'function') {
        return source.cloneNode(true)
      }
      return null
    }

    const clone = getClonedSvg()
    if (!clone) return
    if (initViewBox && initViewBox.length === 4) {
      clone.setAttribute('viewBox', initViewBox.join(' '))
    }
    if (!clone.getAttribute('xmlns')) clone.setAttribute('xmlns', 'http://www.w3.org/2000/svg')
    if (!clone.getAttribute('xmlns:xlink') && clone.outerHTML.includes('xlink:')) {
      clone.setAttribute('xmlns:xlink', 'http://www.w3.org/1999/xlink')
    }
    // inject background to match current theme
    const isDark = document.documentElement.getAttribute('data-theme') === 'dark'
    const bg = getComputedStyle(document.body).backgroundColor || (isDark ? '#1e1e1e' : '#ffffff')
    if (!clone.style.background) clone.style.background = bg

    const serializer = new XMLSerializer()
    const svgSource = serializer.serializeToString(clone)
    const htmlSource = `<!doctype html><html><head><meta charset="utf-8" />
      <style>
        html, body { width: 100%; height: 100%; margin: 0; display: flex; align-items: center; justify-content: center; background: ${bg}; }
        svg { max-width: 100%; max-height: 100%; height: auto; width: auto; }
      </style>
      </head><body>${svgSource}</body></html>`
    const blob = new Blob([htmlSource], { type: 'text/html;charset=utf-8' })
    const url = URL.createObjectURL(blob)
    window.open(url, '_blank', 'noopener')
    setTimeout(() => URL.revokeObjectURL(url), 30000)
  }

  const attachMermaidViewerButton = wrap => {
    let btn = wrap.querySelector('.mermaid-open-btn')
    if (!btn) {
      btn = document.createElement('button')
      btn.type = 'button'
      btn.className = 'mermaid-open-btn'
      wrap.appendChild(btn)
    }

    btn.innerHTML = '<i class="fa fa-search fa-fw" aria-hidden="true"></i>'

    if (!btn.__mermaidViewerBound) {
      btn.addEventListener('click', e => {
        e.preventDefault()
        e.stopPropagation()
        const svg = wrap.__mermaidOriginalSvg || wrap.querySelector('svg')
        if (!svg) return
        const initViewBox = wrap.__mermaidInitViewBox
        if (typeof svg === 'string') {
          openSvgInNewTab({ source: svg, initViewBox })
          return
        }
        openSvgInNewTab({ source: svg, initViewBox })
      })
      btn.__mermaidViewerBound = true
    }
  }

  // Zoom around a point (px, py) in the SVG viewport (in viewBox coordinates)
  const zoomAtPoint = (vb, factor, px, py) => {
    const w = vb[2] * factor
    const h = vb[3] * factor
    const nx = px - (px - vb[0]) * factor
    const ny = py - (py - vb[1]) * factor
    return [nx, ny, w, h]
  }

  const initMermaidGestures = wrap => {
    const svg = wrap.querySelector('svg')
    if (!svg) return

    // Ensure viewBox exists so gestures always work
    const initVb = getSvgViewBox(svg)
    wrap.__mermaidInitViewBox = initVb
    wrap.__mermaidCurViewBox = initVb.slice()
    setSvgViewBox(svg, initVb)

    // Avoid binding multiple times on themeChange/pjax
    if (wrap.__mermaidGestureBound) return
    wrap.__mermaidGestureBound = true

    // Helper: map client (viewport) coordinate -> viewBox coordinate
    const clientToViewBox = (clientX, clientY) => {
      const rect = svg.getBoundingClientRect()
      const vb = wrap.__mermaidCurViewBox || getSvgViewBox(svg)
      const x = vb[0] + (clientX - rect.left) * (vb[2] / rect.width)
      const y = vb[1] + (clientY - rect.top) * (vb[3] / rect.height)
      return { x, y, rect, vb }
    }

    const state = {
      pointers: new Map(),
      startVb: null,
      startDist: 0,
      startCenter: null
    }

    const clampVb = vb => {
      const init = wrap.__mermaidInitViewBox || vb
      const minW = init[2] * 0.1
      const maxW = init[2] * 10
      const minH = init[3] * 0.1
      const maxH = init[3] * 10
      vb[2] = clamp(vb[2], minW, maxW)
      vb[3] = clamp(vb[3], minH, maxH)
      return vb
    }

    const setCurVb = vb => {
      vb = clampVb(vb)
      wrap.__mermaidCurViewBox = vb
      setSvgViewBox(svg, vb)
    }

    const onPointerDown = e => {
      // Allow only primary button for mouse
      if (e.pointerType === 'mouse' && e.button !== 0) return
      svg.setPointerCapture(e.pointerId)
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      if (state.pointers.size === 1) {
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      } else if (state.pointers.size === 2) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        state.startDist = Math.hypot(dx, dy)
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        state.startCenter = { x: (pts[0].x + pts[1].x) / 2, y: (pts[0].y + pts[1].y) / 2 }
      }
    }

    const onPointerMove = e => {
      if (!state.pointers.has(e.pointerId)) return
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      // Pan with 1 pointer
      if (state.pointers.size === 1 && state.startVb) {
        const p = [...state.pointers.values()][0]
        const prev = { x: e.clientX - e.movementX, y: e.clientY - e.movementY }
        // movementX/Y unreliable on touch, compute from stored last position
        const last = wrap.__mermaidLastSinglePointer || p
        const dxClient = p.x - last.x
        const dyClient = p.y - last.y
        wrap.__mermaidLastSinglePointer = p

        const { rect } = clientToViewBox(p.x, p.y)
        const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        const dx = dxClient * (vb[2] / rect.width)
        const dy = dyClient * (vb[3] / rect.height)
        setCurVb([vb[0] - dx, vb[1] - dy, vb[2], vb[3]])
        return
      }

      // Pinch zoom with 2 pointers
      if (state.pointers.size === 2 && state.startVb && state.startDist > 0) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        const dist = Math.hypot(dx, dy)
        if (!dist) return
        const factor = state.startDist / dist // dist bigger => zoom in (viewBox smaller)

        const cx = (pts[0].x + pts[1].x) / 2
        const cy = (pts[0].y + pts[1].y) / 2
        const centerClient = { x: cx, y: cy }

        const pxy = clientToViewBox(centerClient.x, centerClient.y)
        const cpx = pxy.x
        const cpy = pxy.y

        const vb = zoomAtPoint(state.startVb, factor, cpx, cpy)
        setCurVb(vb)
      }
    }

    const onPointerUpOrCancel = e => {
      state.pointers.delete(e.pointerId)
      if (state.pointers.size === 0) {
        state.startVb = null
        state.startDist = 0
        state.startCenter = null
        wrap.__mermaidLastSinglePointer = null
      } else if (state.pointers.size === 1) {
        // reset single pointer baseline to avoid jump
        wrap.__mermaidLastSinglePointer = [...state.pointers.values()][0]
      }
    }

    // Wheel zoom (mouse/trackpad)
    const onWheel = e => {
      // ctrlKey on mac trackpad pinch; we treat both as zoom
      e.preventDefault()
      const delta = e.deltaY
      const zoomFactor = delta > 0 ? 1.1 : 0.9
      const { x, y } = clientToViewBox(e.clientX, e.clientY)
      const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      setCurVb(zoomAtPoint(vb, zoomFactor, x, y))
    }

    const onDblClick = () => {
      const init = wrap.__mermaidInitViewBox
      if (!init) return
      wrap.__mermaidCurViewBox = init.slice()
      setSvgViewBox(svg, init)
    }

    svg.addEventListener('pointerdown', onPointerDown)
    svg.addEventListener('pointermove', onPointerMove)
    svg.addEventListener('pointerup', onPointerUpOrCancel)
    svg.addEventListener('pointercancel', onPointerUpOrCancel)
    svg.addEventListener('wheel', onWheel, { passive: false })
    svg.addEventListener('dblclick', onDblClick)
  }

  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild

      // Clear old render (themeChange/pjax will rerun)
      const oldSvg = item.querySelector('svg')
      if (oldSvg) oldSvg.remove()
      item.__mermaidGestureBound = false

      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
        if (true) initMermaidGestures(item)
        item.__mermaidOriginalSvg = svg
        if (true) attachMermaidViewerButton(item)
      }


      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.4"></script></div></div></body></html>