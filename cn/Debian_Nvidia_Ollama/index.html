

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="henices">
  <meta name="keywords" content="">
  
    <meta name="description" content="根据同事反馈，高版本的 NVIDIA 驱动兼容性有问题，需要安装 Nvidia 驱动 525.147.05 ，过程中可能需要升级内核。 安装 Nvidia 驱动查看 Debian 上显卡安装情况。 12lspci -nn | egrep -i &quot;3d|display|vga&quot;  01:00.0 VGA compatible controller [0300]: NVIDIA C">
<meta property="og:type" content="article">
<meta property="og:title" content="Nvidia 驱动安装和 Ollama 的使用">
<meta property="og:url" content="https://usmacd.com/cn/Debian_Nvidia_Ollama/index.html">
<meta property="og:site_name" content="安全代码">
<meta property="og:description" content="根据同事反馈，高版本的 NVIDIA 驱动兼容性有问题，需要安装 Nvidia 驱动 525.147.05 ，过程中可能需要升级内核。 安装 Nvidia 驱动查看 Debian 上显卡安装情况。 12lspci -nn | egrep -i &quot;3d|display|vga&quot;  01:00.0 VGA compatible controller [0300]: NVIDIA C">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-07-25T16:00:00.000Z">
<meta property="article:modified_time" content="2025-01-01T16:00:00.000Z">
<meta property="article:author" content="henices">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="ai">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Nvidia 驱动安装和 Ollama 的使用 - 安全代码</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"usmacd.com","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":false,"default":"TEXT"},"copy_btn":false,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null},"woyaola":null,"cnzz":null},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="安全代码" type="application/atom+xml">
<link rel="alternate" href="/rss.xml" title="安全代码" type="application/rss+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 40vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>安全代码</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/thoughts" target="_self">
                <i class="iconfont icon-exp-fill"></i>
                <span>thoughts</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/htmls/dailynotes.html" target="_self">
                <i class="iconfont icon-exp-fill"></i>
                <span>weibo</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/rss.xml" target="_self">
                <i class="iconfont icon-rss"></i>
                <span>rss</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/random.html" target="_self">
                
                <span>random</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/sitemap.xml" target="_self">
                
                <span>sitemap</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://images.unsplash.com/photo-1473181488821-2d23949a045a?w=640') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">Nvidia 驱动安装和 Ollama 的使用</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-07-26 00:00" pubdate>
          2024年7月26日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          19 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Nvidia 驱动安装和 Ollama 的使用</h1>
            
              <p id="updated-time" class="note note-info" style="">
                
                  
                    本文最后更新于 2025年1月2日 凌晨
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <p>根据同事反馈，高版本的 NVIDIA 驱动兼容性有问题，需要安装 Nvidia 驱动 525.147.05 ，过程中可能需要升级内核。</p>
<h2 id="安装-Nvidia-驱动"><a href="#安装-Nvidia-驱动" class="headerlink" title="安装 Nvidia 驱动"></a>安装 Nvidia 驱动</h2><p>查看 Debian 上显卡安装情况。</p>
<figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs prolog">lspci -nn | egrep -i <span class="hljs-string">&quot;3d|display|vga&quot;</span>  <br><span class="hljs-number">01</span>:<span class="hljs-number">00.0</span> <span class="hljs-symbol">VGA</span> compatible controller [<span class="hljs-number">0300</span>]: <span class="hljs-symbol">NVIDIA</span> <span class="hljs-symbol">Corporation</span> <span class="hljs-symbol">AD102</span> [<span class="hljs-symbol">GeForce</span> <span class="hljs-symbol">RTX</span> <span class="hljs-number">4090</span>] [<span class="hljs-number">10</span>de:<span class="hljs-number">2684</span>] (rev a1)<br></code></pre></td></tr></table></figure>

<p>查看驱动安装具体的情况。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">lsmod</span> | grep nouveau  <br><span class="hljs-attribute">nouveau</span>              <span class="hljs-number">2433024</span>  <span class="hljs-number">0</span>  <br><span class="hljs-attribute">mxm_wmi</span>                <span class="hljs-number">16384</span>  <span class="hljs-number">1</span> nouveau  <br><span class="hljs-attribute">i2c_algo_bit</span>           <span class="hljs-number">16384</span>  <span class="hljs-number">1</span> nouveau  <br><span class="hljs-attribute">drm_display_helper</span>    <span class="hljs-number">184320</span>  <span class="hljs-number">1</span> nouveau  <br><span class="hljs-attribute">drm_ttm_helper</span>         <span class="hljs-number">16384</span>  <span class="hljs-number">1</span> nouveau  <br><span class="hljs-attribute">ttm</span>                    <span class="hljs-number">94208</span>  <span class="hljs-number">2</span> drm_ttm_helper,nouveau  <br><span class="hljs-attribute">drm_kms_helper</span>        <span class="hljs-number">204800</span>  <span class="hljs-number">2</span> drm_display_helper,nouveau  <br><span class="hljs-attribute">drm</span>                   <span class="hljs-number">614400</span>  <span class="hljs-number">5</span> drm_kms_helper,drm_display_helper,drm_ttm_helper,ttm,nouveau  <br><span class="hljs-attribute">video</span>                  <span class="hljs-number">65536</span>  <span class="hljs-number">2</span> asus_wmi,nouveau  <br><span class="hljs-attribute">wmi</span>                    <span class="hljs-number">36864</span>  <span class="hljs-number">5</span> video,asus_wmi,wmi_bmof,mxm_wmi,nouveau  <br><span class="hljs-attribute">button</span>                 <span class="hljs-number">24576</span>  <span class="hljs-number">1</span> nouveau<br></code></pre></td></tr></table></figure>

<p>看来安装的是开源版本的驱动 <code>nouveau</code>，需要先禁用。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;blacklist nouveau&quot;</span> | <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> /etc/modprobe.d/nouveau-blacklist.conf<br><span class="hljs-built_in">sudo</span> update-initramfs -u<br><span class="hljs-built_in">sudo</span> update-grub<br><span class="hljs-built_in">sudo</span> reboot<br></code></pre></td></tr></table></figure>

<p>重启后，执行 <code>lsmod | grep nouveau</code>  发现已经返回为空了，成功禁用。</p>
<p>执行命令<code> sudo apt install nvidia-driver firmware-misc-nonfree</code> 安装 NVIDIA Proprietary Driver 报错。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Consult</span> /var/lib/dkms/nvidia-current/<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span>/build/make.log for more information.  <br><span class="hljs-attribute">dpkg</span>: error processing package nvidia-kernel-dkms (--configure):  <br><span class="hljs-attribute">installed</span> nvidia-kernel-dkms package post-installation script subprocess returned error exit status <span class="hljs-number">10</span>  <br><span class="hljs-attribute">dpkg</span>: dependency problems prevent configuration of nvidia-driver:  <br><span class="hljs-attribute">nvidia</span>-driver depends <span class="hljs-literal">on</span> nvidia-kernel-dkms (= <span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span>-<span class="hljs-number">4</span>~deb12u1) | nvidia-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span> | nvidia-open-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span> | nvidia-open-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span>; however:  <br> <span class="hljs-attribute">Package</span> nvidia-kernel-dkms is not configured yet.  <br> <span class="hljs-attribute">Package</span> nvidia-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span> is not installed.  <br> <span class="hljs-attribute">Package</span> nvidia-kernel-dkms which provides nvidia-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span> is not configured yet.  <br> <span class="hljs-attribute">Package</span> nvidia-open-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span> is not installed.  <br> <span class="hljs-attribute">Package</span> nvidia-open-kernel-<span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span> is not installed.  <br>  <br><span class="hljs-attribute">dpkg</span>: error processing package nvidia-driver (--configure):  <br><span class="hljs-attribute">dependency</span> problems - leaving unconfigured  <br><span class="hljs-attribute">Processing</span> triggers for libc-bin (<span class="hljs-number">2</span>.<span class="hljs-number">36</span>-<span class="hljs-number">9</span>+deb12u4) ...  <br><span class="hljs-attribute">Processing</span> triggers for initramfs-tools (<span class="hljs-number">0</span>.<span class="hljs-number">142</span>) ...  <br><span class="hljs-attribute">update</span>-initramfs: Generating /boot/initrd.img-<span class="hljs-number">6</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>-<span class="hljs-number">18</span>-amd64  <br><span class="hljs-attribute">Processing</span> triggers for update-glx (<span class="hljs-number">1</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span>) ...  <br><span class="hljs-attribute">Processing</span> triggers for glx-alternative-nvidia (<span class="hljs-number">1</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span>) ...  <br><span class="hljs-attribute">update</span>-alternatives: using /usr/lib/nvidia to provide /usr/lib/glx (glx) in auto mode  <br><span class="hljs-attribute">Processing</span> triggers for glx-alternative-mesa (<span class="hljs-number">1</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span>) ...  <br><span class="hljs-attribute">Processing</span> triggers for libc-bin (<span class="hljs-number">2</span>.<span class="hljs-number">36</span>-<span class="hljs-number">9</span>+deb12u4) ...  <br><span class="hljs-attribute">Processing</span> triggers for initramfs-tools (<span class="hljs-number">0</span>.<span class="hljs-number">142</span>) ...  <br><span class="hljs-attribute">update</span>-initramfs: Generating /boot/initrd.img-<span class="hljs-number">6</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>-<span class="hljs-number">18</span>-amd64  <br><span class="hljs-attribute">Errors</span> were encountered while processing:  <br><span class="hljs-attribute">nvidia</span>-kernel-dkms  <br><span class="hljs-attribute">nvidia</span>-driver  <br><span class="hljs-attribute">E</span>: Sub-process /usr/bin/dpkg returned an error code (<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<p>确认 debian 版本 <code>lsb_release -a</code></p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nix">No LSB modules are available.  <br>Distributor <span class="hljs-params">ID:</span> Debian  <br><span class="hljs-params">Description:</span>    Debian GNU<span class="hljs-symbol">/Linux</span> <span class="hljs-number">12</span> (bookworm)  <br><span class="hljs-params">Release:</span>        <span class="hljs-number">12</span>  <br><span class="hljs-params">Codename:</span>       bookworm<br></code></pre></td></tr></table></figure>

<p>根据 stackexchange 上的回答 ，安全升级 Debian 内核的方法是使用 backports 安装。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;deb http://deb.debian.org/debian bookworm-backports main&quot;</span> | <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/debian-backports.list<br><span class="hljs-built_in">sudo</span> apt update<br><span class="hljs-built_in">sudo</span> apt install -t bookworm-backports linux-image-amd64<br><span class="hljs-built_in">sudo</span> reboot<br></code></pre></td></tr></table></figure>

<p>重新启动后，执行 <code>uname -a</code>  发现内核已经成功升级了。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">uname</span> -a                                                                          <br><span class="hljs-attribute">Linux</span> debian <span class="hljs-number">6</span>.<span class="hljs-number">7</span>.<span class="hljs-number">12</span>+bpo-amd64 #<span class="hljs-number">1</span> SMP PREEMPT_DYNAMIC Debian <span class="hljs-number">6</span>.<span class="hljs-number">7</span>.<span class="hljs-number">12</span>-<span class="hljs-number">1</span>~bpo12+<span class="hljs-number">1</span> (<span class="hljs-number">2024</span>-<span class="hljs-number">05</span>-<span class="hljs-number">06</span>) x86_64 GNU/Linux<br></code></pre></td></tr></table></figure>

<p>重新安装 NVIDIA Proprietary Driver <code>sudo apt install nvidia-driver firmware-misc-nonfree</code> ，这次没有报错了。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">nvidia</span>-smi    <br><br><span class="hljs-attribute">NVIDIA</span>-SMI <span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span>   Driver Version: <span class="hljs-number">525</span>.<span class="hljs-number">147</span>.<span class="hljs-number">05</span>   CUDA Version: <span class="hljs-number">12</span>.<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<p>NVIDIA Proprietary Driver 525 感觉有问题，过了一段时间后机器出现重启现象，dmesg 显示错误 <code>ACPI BIOS Error (bug)</code> 。 </p>
<p>上网搜索错误，有人反馈是 525 驱动问题（不确定）。Debain 系统 Nvidia 驱动有更新，执行 <code>apt upgrade</code> 后成功升级到 535 。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># nvidia-smi</span><br><br><span class="hljs-attribute">NVIDIA</span>-SMI <span class="hljs-number">535</span>.<span class="hljs-number">183</span>.<span class="hljs-number">01</span>             Driver Version: <span class="hljs-number">535</span>.<span class="hljs-number">183</span>.<span class="hljs-number">01</span>   CUDA Version: <span class="hljs-number">12</span>.<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>

<p>升级 Nvidia 驱动到 535 后，暂未出现重启现象。</p>
<h2 id="安装-ollama"><a href="#安装-ollama" class="headerlink" title="安装 ollama"></a>安装 ollama</h2><p>执行下面的命令安装 Ollama</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">curl -fsSL https://ollama.com/install.sh | sh<br></code></pre></td></tr></table></figure>

<p>下载速度很慢，还是挂线路。</p>
<figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade"><span class="hljs-keyword">export</span> https_proxy=http:<span class="hljs-comment">//127.0.0.1:7890</span><br><span class="hljs-keyword">export</span> http_proxy=http:<span class="hljs-comment">//127.0.0.1:7890</span><br>curl -fsSL https:<span class="hljs-comment">//ollama.com/install.sh | sh</span><br></code></pre></td></tr></table></figure>

<p>挂上线路后，很快 Ollama 就安装成功了。</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs clean">&gt;&gt;&gt; Downloading ollama...  <br>######################################################################## <span class="hljs-number">100.0</span>%#=#=-#  #                                                                        <br>&gt;&gt;&gt; Installing ollama to /usr/local/bin...  <br>&gt;&gt;&gt; Creating ollama user...  <br>&gt;&gt;&gt; Adding ollama user to render group...  <br>&gt;&gt;&gt; Adding ollama user to video group...  <br>&gt;&gt;&gt; Adding current user to ollama group...  <br>&gt;&gt;&gt; Creating ollama systemd service...  <br>&gt;&gt;&gt; Enabling and starting ollama service...  <br>Created symlink /etc/systemd/<span class="hljs-keyword">system</span>/default.target.wants/ollama.service → /etc/systemd/<span class="hljs-keyword">system</span>/ollama.service.  <br>&gt;&gt;&gt; NVIDIA GPU installed.<br></code></pre></td></tr></table></figure>

<p>ollama 下载 llama3 8b 和 qwen2 7b 模型，执行下面的命令：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ollama</span> pull llama3<br><span class="hljs-attribute">ollama</span> pull qwen2:<span class="hljs-number">7</span>b<br></code></pre></td></tr></table></figure>

<p>测试 llama3 模型，运行正常。</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">ollama run llama3  <br>&gt;&gt;&gt; hi  <br>Hi! It<span class="hljs-comment">&#x27;s nice to meet you. Is there something I can help you with or would you like to chat?</span><br></code></pre></td></tr></table></figure>
<h2 id="升级-Ollama"><a href="#升级-Ollama" class="headerlink" title="升级 Ollama"></a>升级 Ollama</h2><p>Ollama 0.3.0 支持通过 llama3.1 进行工具调用，有必要升级。参见 [4]</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/local/bin/ollama<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">chmod</span> +x /usr/local/bin/ollama<br></code></pre></td></tr></table></figure>

<p>升级完毕，需要重启 Ollama 服务。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> systemctl daemon-reload<br><span class="hljs-built_in">sudo</span> systemctl restart ollama<br></code></pre></td></tr></table></figure>

<p>新版本的 Ollama 已经不是一个单独的文件，而是一个 <code>tar.gz</code> 的压缩包。<br>tar.tgz 中包含了 ollama 运行需要的动态库，在升级前需要将这些动态库删除。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -rf /usr/lib/ollama<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -rf /usr/local/lib/ollama<br><br>curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz<br><span class="hljs-built_in">sudo</span> tar -C /usr/local -xzf ollama-linux-amd64.tgz<br></code></pre></td></tr></table></figure>

<p>执行完上述命令后，启动 ollama 检查版本确认是否升级成功。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">ollama serve<br>ollama -v<br></code></pre></td></tr></table></figure>

<h2 id="配置-Ollama"><a href="#配置-Ollama" class="headerlink" title="配置 Ollama"></a>配置 Ollama</h2><p>如果需要在浏览器插件（比如沉浸翻译）中调用 Ollama api，涉及 Cross-Origin 访问，需要修改 Ollama 配置。</p>
<p>官方文档提到了相关的设置 [5]，用 vim 直接修改 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ollama.service 中，添加下面内容：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_HOST=*&quot;</span><br></code></pre></td></tr></table></figure>

<p>重启 Ollama 服务</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> systemctl daemon-reload<br><span class="hljs-built_in">sudo</span> systemctl restart ollama<br></code></pre></td></tr></table></figure>

<p>在远程主机上，查看 Ollama 端口侦听情况</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">apt install net-tools<br>netstat -antp | grep -i ollama  <br></code></pre></td></tr></table></figure>

<p>Ollama 默认侦听 127.0.0.1:11434</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tcp</span>        <span class="hljs-number">0</span>      <span class="hljs-number">0</span> <span class="hljs-number">127.0.0.1:11434</span>         <span class="hljs-number">0.0.0.0</span>:*               LISTEN      <span class="hljs-number">50508</span>/ollama<br></code></pre></td></tr></table></figure>

<p>利用 SSH 将远程主机 Ollama 侦听的端口 11434 转发到本地 127.0.0.1:11434</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">ssh -N -g -L 127.0.0.1:11434:127.0.0.1:11434 root@1.1.1.1  <span class="hljs-comment"># 将 1.1.1.1 替换成你的 ip</span><br></code></pre></td></tr></table></figure>
<h2 id="卸载-Ollama"><a href="#卸载-Ollama" class="headerlink" title="卸载 Ollama"></a>卸载 Ollama</h2><p>停止 Ollama 服务</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> systemctl stop ollama<br><span class="hljs-built_in">sudo</span> systemctl <span class="hljs-built_in">disable</span> ollama<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> /etc/systemd/system/ollama.service<br></code></pre></td></tr></table></figure>

<p>删除二进制文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> $(<span class="hljs-built_in">which</span> ollama)<br></code></pre></td></tr></table></figure>

<p>删除 Ollama 用户</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -r /usr/share/ollama<br><span class="hljs-built_in">sudo</span> userdel ollama<br><span class="hljs-built_in">sudo</span> groupdel ollama<br></code></pre></td></tr></table></figure>

<h2 id="Ollama-的使用"><a href="#Ollama-的使用" class="headerlink" title="Ollama 的使用"></a>Ollama 的使用</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">OLLAMA_ORIGINS=* OLLAMA_NUM_PARALLEL=16 ollama serve<br></code></pre></td></tr></table></figure>

<ul>
<li>OLLAMA_ORIGINS 跨域设置</li>
<li>OLLAMA_NUM_PARALLEL 支持的并行请求数量</li>
<li>OLLAMA_DEBUG 打印调试信息</li>
<li>OLLAMA_LLM_LIBRARY 支持下面的选项  rocm_v6 cpu cpu_avx cpu_avx2 cuda_v11 rocm_v5</li>
<li>OLLAMA_KEEP_ALIVE 模型在显存内加载的时间，默认为 5 分钟</li>
<li>OLLAMA_GPU_OVERHEAD 单独为每个 GPU 预留的 VRAM ，单位是字节</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/blob/main/envconfig/config.go">https://github.com/ollama/ollama/blob/main/envconfig/config.go</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">AsMap</span><span class="hljs-params">()</span></span> <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]EnvVar &#123;<br>	ret := <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]EnvVar&#123;<br>		<span class="hljs-string">&quot;OLLAMA_DEBUG&quot;</span>:             &#123;<span class="hljs-string">&quot;OLLAMA_DEBUG&quot;</span>, Debug(), <span class="hljs-string">&quot;Show additional debug information (e.g. OLLAMA_DEBUG=1)&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_FLASH_ATTENTION&quot;</span>:   &#123;<span class="hljs-string">&quot;OLLAMA_FLASH_ATTENTION&quot;</span>, FlashAttention(), <span class="hljs-string">&quot;Enabled flash attention&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_HOST&quot;</span>:              &#123;<span class="hljs-string">&quot;OLLAMA_HOST&quot;</span>, Host(), <span class="hljs-string">&quot;IP Address for the ollama server (default 127.0.0.1:11434)&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_KEEP_ALIVE&quot;</span>:        &#123;<span class="hljs-string">&quot;OLLAMA_KEEP_ALIVE&quot;</span>, KeepAlive(), <span class="hljs-string">&quot;The duration that models stay loaded in memory (default \&quot;5m\&quot;)&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_LLM_LIBRARY&quot;</span>:       &#123;<span class="hljs-string">&quot;OLLAMA_LLM_LIBRARY&quot;</span>, LLMLibrary(), <span class="hljs-string">&quot;Set LLM library to bypass autodetection&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_MAX_LOADED_MODELS&quot;</span>: &#123;<span class="hljs-string">&quot;OLLAMA_MAX_LOADED_MODELS&quot;</span>, MaxRunners(), <span class="hljs-string">&quot;Maximum number of loaded models per GPU&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_MAX_QUEUE&quot;</span>:         &#123;<span class="hljs-string">&quot;OLLAMA_MAX_QUEUE&quot;</span>, MaxQueue(), <span class="hljs-string">&quot;Maximum number of queued requests&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_MODELS&quot;</span>:            &#123;<span class="hljs-string">&quot;OLLAMA_MODELS&quot;</span>, Models(), <span class="hljs-string">&quot;The path to the models directory&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_NOHISTORY&quot;</span>:         &#123;<span class="hljs-string">&quot;OLLAMA_NOHISTORY&quot;</span>, NoHistory(), <span class="hljs-string">&quot;Do not preserve readline history&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_NOPRUNE&quot;</span>:           &#123;<span class="hljs-string">&quot;OLLAMA_NOPRUNE&quot;</span>, NoPrune(), <span class="hljs-string">&quot;Do not prune model blobs on startup&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_NUM_PARALLEL&quot;</span>:      &#123;<span class="hljs-string">&quot;OLLAMA_NUM_PARALLEL&quot;</span>, NumParallel(), <span class="hljs-string">&quot;Maximum number of parallel requests&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_ORIGINS&quot;</span>:           &#123;<span class="hljs-string">&quot;OLLAMA_ORIGINS&quot;</span>, Origins(), <span class="hljs-string">&quot;A comma separated list of allowed origins&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_RUNNERS_DIR&quot;</span>:       &#123;<span class="hljs-string">&quot;OLLAMA_RUNNERS_DIR&quot;</span>, RunnersDir(), <span class="hljs-string">&quot;Location for runners&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_SCHED_SPREAD&quot;</span>:      &#123;<span class="hljs-string">&quot;OLLAMA_SCHED_SPREAD&quot;</span>, SchedSpread(), <span class="hljs-string">&quot;Always schedule model across all GPUs&quot;</span>&#125;,<br>		<span class="hljs-string">&quot;OLLAMA_TMPDIR&quot;</span>:            &#123;<span class="hljs-string">&quot;OLLAMA_TMPDIR&quot;</span>, TmpDir(), <span class="hljs-string">&quot;Location for temporary files&quot;</span>&#125;,<br>	&#125;<br>	<span class="hljs-keyword">if</span> runtime.GOOS != <span class="hljs-string">&quot;darwin&quot;</span> &#123;<br>		ret[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>, CudaVisibleDevices(), <span class="hljs-string">&quot;Set which NVIDIA devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;HIP_VISIBLE_DEVICES&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;HIP_VISIBLE_DEVICES&quot;</span>, HipVisibleDevices(), <span class="hljs-string">&quot;Set which AMD devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;ROCR_VISIBLE_DEVICES&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;ROCR_VISIBLE_DEVICES&quot;</span>, RocrVisibleDevices(), <span class="hljs-string">&quot;Set which AMD devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;GPU_DEVICE_ORDINAL&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;GPU_DEVICE_ORDINAL&quot;</span>, GpuDeviceOrdinal(), <span class="hljs-string">&quot;Set which AMD devices are visible&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;HSA_OVERRIDE_GFX_VERSION&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;HSA_OVERRIDE_GFX_VERSION&quot;</span>, HsaOverrideGfxVersion(), <span class="hljs-string">&quot;Override the gfx used for all detected AMD GPUs&quot;</span>&#125;<br>		ret[<span class="hljs-string">&quot;OLLAMA_INTEL_GPU&quot;</span>] = EnvVar&#123;<span class="hljs-string">&quot;OLLAMA_INTEL_GPU&quot;</span>, IntelGPU(), <span class="hljs-string">&quot;Enable experimental Intel GPU detection&quot;</span>&#125;<br>	&#125;<br>	<span class="hljs-keyword">return</span> ret<br>&#125;<br></code></pre></td></tr></table></figure>

<p>可以使用 <code>ollama serve -h</code> 查看官方明确支持的环境变量。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs sh">ollama serve -h  <br>Start ollama  <br>  <br>Usage:  <br> ollama serve [flags]  <br>  <br>Aliases:  <br> serve, start  <br>  <br>Flags:  <br> -h, --<span class="hljs-built_in">help</span>   <span class="hljs-built_in">help</span> <span class="hljs-keyword">for</span> serve  <br>  <br>Environment Variables:  <br>     OLLAMA_DEBUG               Show additional debug information (e.g. OLLAMA_DEBUG=1)  <br>     OLLAMA_HOST                IP Address <span class="hljs-keyword">for</span> the ollama server (default 127.0.0.1:11434)  <br>     OLLAMA_KEEP_ALIVE          The duration that models stay loaded <span class="hljs-keyword">in</span> memory (default <span class="hljs-string">&quot;5m&quot;</span>)  <br>     OLLAMA_MAX_LOADED_MODELS   Maximum number of loaded models per GPU  <br>     OLLAMA_MAX_QUEUE           Maximum number of queued requests  <br>     OLLAMA_MODELS              The path to the models directory  <br>     OLLAMA_NUM_PARALLEL        Maximum number of parallel requests  <br>     OLLAMA_NOPRUNE             Do not prune model blobs on startup  <br>     OLLAMA_ORIGINS             A comma separated list of allowed origins  <br>     OLLAMA_SCHED_SPREAD        Always schedule model across all GPUs  <br>                                   <br>     OLLAMA_FLASH_ATTENTION     Enabled flash attention  <br>     OLLAMA_KV_CACHE_TYPE       Quantization <span class="hljs-built_in">type</span> <span class="hljs-keyword">for</span> the K/V cache (default: f16)  <br>     OLLAMA_LLM_LIBRARY         Set LLM library to bypass autodetection  <br>     OLLAMA_GPU_OVERHEAD        Reserve a portion of VRAM per GPU (bytes)  <br>     OLLAMA_LOAD_TIMEOUT        How long to allow model loads to stall before giving up (default <span class="hljs-string">&quot;5m&quot;</span>)<br></code></pre></td></tr></table></figure>


<h3 id="切换-Ollama-的模型文件位置"><a href="#切换-Ollama-的模型文件位置" class="headerlink" title="切换 Ollama 的模型文件位置"></a>切换 Ollama 的模型文件位置</h3><ul>
<li>OLLAMA_MODELS 环境变量可以修改模型文件下载的位置。</li>
</ul>
<p>先把选择下载的模型文件移动到新创建的 <code>/mnt/disk</code> , 默认存在的位置是  <code>~/.ollama/models</code><br>（使用 Ollama 官方的脚本安装，默认路径是 <code>/usr/share/ollama/.ollama/</code>）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mv</span> ~/.ollama/ /mnt/disk/<br><span class="hljs-built_in">ln</span> -s /mnt/disk/.ollama ~/.ollama<br></code></pre></td></tr></table></figure>

<p>重新 Ollama 启动测试</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">NVIDIA_VISIBLE_DEVICES</span>=<span class="hljs-literal">all</span> CUDA_VISIBLE_DEVICES=<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span> OLLAMA_ORIGINS=* OLLAMA_NUM_PARALLEL=<span class="hljs-number">16</span> OLLAMA_KEEP_ALIVE=<span class="hljs-number">10</span>m ollama serve<br></code></pre></td></tr></table></figure>

<p>测试成功。</p>
<figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs monkey">root@pm-<span class="hljs-number">65</span>c50001:~<span class="hljs-meta"># ollama run llama3:8b-instruct-fp16  </span><br>&gt;&gt;&gt; hi  <br>Hi! It<span class="hljs-comment">&#x27;s nice to meet you. Is there something I can help you with or would you like to chat?</span><br></code></pre></td></tr></table></figure>

<h3 id="研究-Ollama-mutlple-GPU"><a href="#研究-Ollama-mutlple-GPU" class="headerlink" title="研究 Ollama mutlple GPU"></a>研究 Ollama mutlple GPU</h3><p>在 <a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/issues/4198">https://github.com/ollama/ollama/issues/4198</a> 中发现一些比较重要的环境变量。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Unit]</span>  <br><span class="hljs-attr">Description</span>=Ollama Service  <br><span class="hljs-attr">After</span>=network-<span class="hljs-literal">on</span>line.target<br><br><span class="hljs-section">[Service]</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_HOST=0.0.0.0:11434&quot;</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_ORIGINS=&#x27;*&#x27;&quot;</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_MODELS=/ollama/ollama/models&quot;</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_KEEP_ALIVE=10m&quot;</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_NUM_PARALLEL=4&quot;</span><br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;OLLAMA_MAX_LOADED_MODELS=2&quot;</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES=0,1,2,3&quot;</span>  <br><span class="hljs-attr">ExecStart</span>=/usr/local/bin/ollama serve  <br><span class="hljs-attr">User</span>=ollama  <br><span class="hljs-attr">Group</span>=ollama  <br><span class="hljs-attr">Restart</span>=always  <br><span class="hljs-attr">RestartSec</span>=<span class="hljs-number">3</span>  <br><span class="hljs-attr">Environment</span>=<span class="hljs-string">&quot;PATH=/root/.local/bin:/root/bin:/usr/lib64/ccache:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin&quot;</span><br><br><span class="hljs-section">[Install]</span>  <br><span class="hljs-attr">WantedBy</span>=default.target<br></code></pre></td></tr></table></figure>

<p>综合一下，决定使用下面的命令行：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">NVIDIA_VISIBLE_DEVICES</span>=<span class="hljs-literal">all</span> CUDA_VISIBLE_DEVICES=<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span> OLLAMA_ORIGINS=* OLLAMA_NUM_PARALLEL=<span class="hljs-number">16</span> OLLAMA_KEEP_ALIVE=<span class="hljs-number">10</span>m ollama serve<br></code></pre></td></tr></table></figure>

<h3 id="如何判断模型是否加载入-GPU"><a href="#如何判断模型是否加载入-GPU" class="headerlink" title="如何判断模型是否加载入 GPU"></a>如何判断模型是否加载入 GPU</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ollama</span> ps<br><span class="hljs-attribute">NAME</span>      	ID          	SIZE 	PROCESSOR	UNTIL<br><span class="hljs-attribute">llama3</span>:<span class="hljs-number">70</span>b	bcfb190ca3a7	<span class="hljs-number">42</span> GB	<span class="hljs-number">100</span>% GPU 	<span class="hljs-number">4</span> minutes from now<br></code></pre></td></tr></table></figure>

<ul>
<li>48%&#x2F;52% CPU&#x2F;GPU 类似这样的显示，说明模型只有部分加载入 GPU，还有一部分加载入系统的内存</li>
</ul>
<h3 id="内核设置-numa-balancing"><a href="#内核设置-numa-balancing" class="headerlink" title="内核设置 numa_balancing"></a>内核设置 numa_balancing</h3><p>Ollama 0.3.6 加载  Llama 3.1 405b 失败，界面一直卡着不动，在 Github 上看到类似问题。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/issues/6425">https://github.com/ollama/ollama/issues/6425</a></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">time</span>=<span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">29</span>T10:<span class="hljs-number">50</span>:<span class="hljs-number">24</span>.<span class="hljs-number">720</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=INFO source=sched.go:<span class="hljs-number">445</span> msg=<span class="hljs-string">&quot;loaded runners&quot;</span> count=<span class="hljs-number">1</span><br><span class="hljs-attribute">time</span>=<span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">29</span>T10:<span class="hljs-number">50</span>:<span class="hljs-number">24</span>.<span class="hljs-number">720</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=INFO source=server.go:<span class="hljs-number">593</span> msg=<span class="hljs-string">&quot;waiting for llama runner to start responding&quot;</span><br><span class="hljs-attribute">time</span>=<span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">29</span>T10:<span class="hljs-number">50</span>:<span class="hljs-number">24</span>.<span class="hljs-number">720</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=INFO source=server.go:<span class="hljs-number">627</span> msg=<span class="hljs-string">&quot;waiting for server to become available&quot;</span> status=<span class="hljs-string">&quot;llm server error&quot;</span><br><span class="hljs-attribute">WARNING</span>: /proc/sys/kernel/numa_balancing is enabled, this has been observed to impair performance<br></code></pre></td></tr></table></figure>

<p>上面的 Issue 提到   有影响，手工禁用并使用 Ollama 0.3.8 可以解决问题。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> 0 &gt; /proc/sys/kernel/numa_balancing  <span class="hljs-comment"># or</span><br>sysctl -w kernel.numa_balancing=0<br></code></pre></td></tr></table></figure>

<p>学习 <code>/numa_balancing</code> 的作用，看上去像优化内存使用。<br><a target="_blank" rel="noopener" href="https://docs.kernel.org/admin-guide/sysctl/kernel.html#numa-balancing">https://docs.kernel.org/admin-guide/sysctl/kernel.html#numa-balancing</a></p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">Enables/disables <span class="hljs-keyword">and</span> configures <span class="hljs-built_in">auto</span>matic page fault based NUMA memory balancing<br></code></pre></td></tr></table></figure>

<p>Ollama 从 0.37 开始不再是一个独立的 X86_64 的 elf，而是一个 tar.gz<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/releases/download/v0.3.8/ollama-linux-amd64.tgz">https://github.com/ollama/ollama/releases/download/v0.3.8/ollama-linux-amd64.tgz</a></p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># cd root</span><br><span class="hljs-comment"># tar zxvf ollama-linux-amd64.tgz    </span><br><span class="hljs-string">./</span>  <br><span class="hljs-string">./lib/</span>  <br><span class="hljs-string">./lib/ollama/</span>  <br><span class="hljs-string">./lib/ollama/libcublas.so.12.4.2.65</span>  <br><span class="hljs-string">./lib/ollama/libcublasLt.so.11</span>  <br><span class="hljs-string">./lib/ollama/libcublas.so.11.5.1.109</span>  <br><span class="hljs-string">./lib/ollama/libcudart.so.11.3.109</span>  <br><span class="hljs-string">./lib/ollama/libcublas.so.12</span>  <br><span class="hljs-string">./lib/ollama/libcublasLt.so</span>  <br><span class="hljs-string">./lib/ollama/libcublas.so.11</span>  <br><span class="hljs-string">./lib/ollama/libcublas.so</span>  <br><span class="hljs-string">./lib/ollama/libcudart.so</span>  <br><span class="hljs-string">./lib/ollama/libcublasLt.so.12</span>  <br><span class="hljs-string">./lib/ollama/libcublasLt.so.11.5.1.109</span>  <br><span class="hljs-string">./lib/ollama/libcudart.so.11.0</span>  <br><span class="hljs-string">./lib/ollama/libcudart.so.12.4.99</span>  <br><span class="hljs-string">./lib/ollama/libcudart.so.12</span>  <br><span class="hljs-string">./lib/ollama/libcublasLt.so.12.4.2.65</span>  <br><span class="hljs-string">./bin/</span>  <br><span class="hljs-string">./bin/ollama</span><br></code></pre></td></tr></table></figure>


<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#export LD_LIBRARY_PATH=/root/lib/ollama/</span><br>OLLAMA_DEBUG=1 NVIDIA_VISIBLE_DEVICES=all CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 OLLAMA_ORIGINS=* OLLAMA_KEEP_ALIVE=10m /root/bin/ollama serve<br></code></pre></td></tr></table></figure>

<p>34s 后，Llama3.1 405b 成功启动</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">time</span>=<span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">29</span>T15:<span class="hljs-number">07</span>:<span class="hljs-number">02</span>.<span class="hljs-number">113</span>+<span class="hljs-number">08</span>:<span class="hljs-number">00</span> level=INFO source=server.go:<span class="hljs-number">630</span> msg=<span class="hljs-string">&quot;llama runner started in 34.94 seconds&quot;</span><br></code></pre></td></tr></table></figure>


<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[0] NvidiaGraphicsDrivers<br><a target="_blank" rel="noopener" href="https://wiki.debian.org/NvidiaGraphicsDrivers">https://wiki.debian.org/NvidiaGraphicsDrivers</a></p>
<p>[1] Debain backports Instructions<br><a target="_blank" rel="noopener" href="https://backports.debian.org/Instructions/">https://backports.debian.org/Instructions/</a></p>
<p>[2] Ollama on Linux<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/blob/main/docs/linux.md">https://github.com/ollama/ollama/blob/main/docs/linux.md</a></p>
<p>[3] Is it possible &amp; safe to use latest kernel with Debian?<br><a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/725783/is-it-possible-safe-to-use-latest-kernel-with-debian">https://unix.stackexchange.com/questions/725783/is-it-possible-safe-to-use-latest-kernel-with-debian</a></p>
<p>[4] Ollama v0.3.0 release note<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/releases/tag/v0.3.0">https://github.com/ollama/ollama/releases/tag/v0.3.0</a></p>
<p>[5] Ollama FAQ<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server">https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/linux/" class="print-no-link">#linux</a>
      
        <a href="/tags/ai/" class="print-no-link">#ai</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Nvidia 驱动安装和 Ollama 的使用</div>
      <div>https://usmacd.com/cn/Debian_Nvidia_Ollama/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>henices</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年7月26日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/cn/android_apk_extract/" title="如何提取 Android 手机中已经安装的 APK 文件">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">如何提取 Android 手机中已经安装的 APK 文件</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/cn/elon_philosophy/" title="马斯克的哲学">
                        <span class="hidden-mobile">马斯克的哲学</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  




  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
